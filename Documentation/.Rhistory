filter(Year != 2023)
#Convert column from character to numeric
mu$Unemployment <- as.numeric(mu$Unemployment)
#Round data to second decimal
mu$Unemployment <- round(mu$Unemployment, digits = 2)
#Maryland Labor Force
ml <- read.csv("maryland_labor.csv") %>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Labor
rename(Labor = LBSSA24)
#Remove 2023 Which is NA
ml <- ml %>%
filter(Year != 2023)
#Convert column from character to numeric
ml$Labor <- as.numeric(ml$Labor)
#Round data to second decimal
ml$Labor <- round(ml$Labor, digits = 2)
#Maryland Crime Only Year and Grand Total
crimeTotalm <- crimeTotalm_raw[, c(1:3,11,39:41)]
#Merge Unemployment with Yearly crime
crimeTotalm <- merge(x = mu, y = crimeTotalm, by = "Year", all.y = TRUE)
#Merge Labor force with Unemployment and Yearly Crime
crimeTotalm <- merge(x = ml, y = crimeTotalm, by = "Year",
all.y = TRUE)
countylist <- unique(crimeTotalm$JURISDICTION)
# Create an empty data frame to store results
correlation_data <- data.frame(JURISDICTION = character(),
correlation = numeric(),
average_population = numeric(),
stringsAsFactors = FALSE)
for (i in seq_along(countylist)) {
county_data <- crimeTotalm %>%
filter(JURISDICTION == countylist[i])
# Calculate correlation
correlation_value <- cor(county_data$Labor, county_data$GRAND.TOTAL)
# Calculate average population
average_population <- mean(county_data$POPULATION)
# Append the results to the correlation_data data frame
correlation_data <- bind_rows(correlation_data,
data.frame(JURISDICTION = countylist[i],
correlation = correlation_value,
average_population = average_population))
}
#New York Unemployment
nu <- read.csv("NYUR.csv")%>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Unemployment
rename(Unemployment = NYUR)
#Remove 2023 Which is NA
nu <- nu %>%
filter(Year != 2023)
#Convert column from character to numeric
nu$Unemployment <- as.numeric(nu$Unemployment)
#Round data to second decimal
nu$Unemployment <- round(nu$Unemployment, digits = 2)
#New York Labor Force
nl <- read.csv("newyork_labor.csv") %>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Labor
rename(Labor = LBSSA36)
#Remove 2023 Which is NA
nl <- nl %>%
filter(Year != 2023)
#Convert column from character to numeric
nl$Labor <- as.numeric(nl$Labor)
#Round data to second decimal
nl$Labor <- round(nl$Labor, digits = 2)
#Washington Unemployment
wu <- read.csv("WAUR.csv")%>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Unemployment
rename(Unemployment = WAUR)
#Remove 2023 Which is NA
wu <- wu %>%
filter(Year != 2023)
#Convert column from character to numeric
wu$Unemployment <- as.numeric(wu$Unemployment)
#Round data to second decimal
wu$Unemployment <- round(wu$Unemployment, digits = 2)
#Washington Labor Force
wl <- read.csv("washington_labor.csv") %>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Labor
rename(Labor = LBSSA53)
#Remove 2023 Which is NA
wl <- wl %>%
filter(Year != 2023)
#Convert column from character to numeric
wl$Labor <- as.numeric(wl$Labor)
#Round data to second decimal
wl$Labor <- round(wl$Labor, digits = 2)
#Washington
#Washington crime that only leaves state totals and renames columns
yearly_crime_w_raw <- read.csv("washington_state_crime.csv") %>%
rename(Year = year)
yearly_crime_w <- yearly_crime_w_raw %>%
group_by(Year) %>%
filter(county == "STATE")
#Create data set the contains all Data from the SRS reporting system 1990-2011
yearly_crime_w_srs <- yearly_crime_w[c(1:22),c(1,3,22)] %>%
rename(yearly_crime = SRS_TOTAL)
#Create data set that contains all Data from the NIBRS system starting in 2012-2020
yearly_crime_w_nib <- yearly_crime_w[c(23:33),c(1,3,46)] %>%
rename(yearly_crime = NIB_TOTAL)
#Combine both Datasets
yearly_crime_w_clean <- rbind.data.frame(yearly_crime_w_nib,yearly_crime_w_srs)
#Order Data set by Year
yearly_crime_w_clean <- yearly_crime_w_clean[order(yearly_crime_w_clean$Year), ]
#Merge Unemployment with Yearly crime
washington <- merge(x = wu, y = yearly_crime_w_clean, by = "Year", all.y = TRUE)
#Merge Labor force with Unemployment and Yearly Crime
washington <- merge(x = wl, y = washington, by = "Year",
all.y = TRUE)
#New York Crime w/ Grand Total
yearly_crime_n_raw <- read.csv("new york crime.csv")
yearly_crime_n <- yearly_crime_n_raw %>%
group_by(Year) %>%
mutate(yearly_crime = sum(Index_Count)) %>%
mutate(yearly_pop = sum(Population))
#New York Crime Only Year and Grand Total
yearly_crime_n_clean <- yearly_crime_n[c(1:33), c(2,12, 13)]
#Merge Unemployment with Yearly crime
newyork <- merge(x = nu, y = yearly_crime_n_clean, by = "Year", all.y = TRUE)
#Merge Labor force with Unemployment and Yearly Crime
newyork <- merge(x = nl, y = newyork, by = "Year",
all.y = TRUE)
newyork_noagg <- merge(x = nu, y = yearly_crime_n_raw, by = "Year", all.y = TRUE)
newyork_noagg <- merge(x = nl, y = newyork_noagg, by = "Year", all.y = TRUE)
pca_crime <- crimeTotalm_raw
pca_crime <- merge(x = mu, y = pca_crime, by = "Year", all.y = TRUE)
pca_crime <- merge(x = ml, y = pca_crime, by = "Year", all.y = TRUE)
selected_columns5 <- pca_crime[, c("POPULATION","Labor","Unemployment")]
scaled_data <- scale(selected_columns5)
pca_results <- prcomp(scaled_data, center = TRUE, scale. = TRUE)
principal_components <- pca_results$x
biplot(pca_results)
#1
print("Overall Crime")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$GRAND.TOTAL)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
#2
print("Breaking and Entering")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$B...E)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
#3
print("Larceny Theft")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$LARCENY.THEFT)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
#4
print("Robbery")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$ROBBERY)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
#5
print("Murder")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$MURDER)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
#6
print("Aggrevated Assualt")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$AGG..ASSAULT)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
#7
print("MV THEFT")
regression_crime <- data.frame(principal_components, grand.total = pca_crime$M.V.THEFT)
lm_model <- lm(grand.total ~ ., data = regression_crime)
summary(lm_model)
# New York
setwd("X:/Coding/Rstudio/R Projects/Data 490 Model Building/Documentation")
#New York Crime w/ Grand Total
yearly_crime_n_raw <- read.csv("new york crime.csv")
yearly_crime_n <- yearly_crime_n_raw %>%
group_by(Year) %>%
mutate(yearly_crime = sum(Index_Count))
#New York Unemployment
nu <- read.csv("NYUR.csv")%>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Unemployment
rename(Unemployment = NYUR)
#Remove 2023 Which is NA
nu <- nu %>%
filter(Year != 2023)
#Convert column from character to numeric
nu$Unemployment <- as.numeric(nu$Unemployment)
#Round data to second decimal
nu$Unemployment <- round(nu$Unemployment, digits = 2)
#New York Labor Force
nl <- read.csv("newyork_labor.csv") %>%
#Converts the Date Column from a Date to a Year
mutate(DATE = year(DATE)) %>%
#Changes the Date Column name to Year
rename(Year = DATE) %>%
#Rename column to Labor
rename(Labor = LBSSA36)
#Remove 2023 Which is NA
nl <- nl %>%
filter(Year != 2023)
#Convert column from character to numeric
nl$Labor <- as.numeric(nl$Labor)
#Round data to second decimal
nl$Labor <- round(nl$Labor, digits = 2)
# Left join 'yearly_crime_n_raw' with 'nu' based on the 'Year' column
yearly_crime_n_raw <- left_join(yearly_crime_n_raw, nl, by = 'Year')
# Left join 'yearly_crime_n_raw' with 'nu' based on the 'Year' column
yearly_crime_n_raw <- left_join(yearly_crime_n_raw, nu, by = 'Year')
results <- yearly_crime_n_raw %>%
group_by(County) %>%
summarize(mean_population = mean(Population)) %>%
arrange(desc(mean_population))
summary(results)
#Breaks the the counties into four groups
for( i in seq_along(results$mean_population)) {
if (results$mean_population[i] > 232099) {
results$pop_group[i] = 4
}else if(results$mean_population[i] > 91082){
results$pop_group[i] = 3
}else if(results$mean_population[i] > 50689){
results$pop_group[i] = 2
}else if(results$mean_population[i] <= 50689 ){
results$pop_group[i] = 1}
}
# Merge the two data frames on the 'County' column
merged_data <- merge(yearly_crime_n_raw, results[, c('County', 'pop_group')], by = 'County', all.x = TRUE)
# Print the merged data frame
pop_groups <- unique(merged_data$pop_group)
# Create an empty list to store regression models
regression_models <- list()
# Iterate through each population group and fit a Poisson regression model
for (group in pop_groups) {
subset_data <- filter(merged_data, pop_group == group)
model <- glm(Index_Count ~ Unemployment + Labor + Population, data = subset_data, family = poisson(link = "log"))
regression_models[[group]] <- model
# Print summary for each model with the corresponding group
cat("Summary for", group, ":\n")
print(summary(model))
cat("\n")
}
count_by_pop_group <- table(results$pop_group)
print(count_by_pop_group)
pop_groups <- unique(merged_data$pop_group)
# Create an empty list to store regression models
regression_models <- list()
# Iterate through each population group and fit a Negative Binomial regression model
for (group in pop_groups) {
subset_data <- filter(merged_data, pop_group == group)
# Fit Negative Binomial Regression
model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = subset_data)
regression_models[[group]] <- model
# Print summary for each model with the corresponding group
cat("Summary for", group, ":\n")
print(summary(model))
cat("\n")
}
# (Assuming 'results' is the correct dataframe to use for count_by_pop_group)
count_by_pop_group <- table(results$pop_group)
print(count_by_pop_group)
ny_agg <- glm.nb(yearly_crime ~ Unemployment + Labor + yearly_pop , data = newyork)
ny_noagg <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = newyork_noagg)
summary(ny_agg)
summary(ny_noagg)
confusionMatrixPlot <- function(cm) {
ggplot() +
geom_tile(aes(x = Prediction, y = Reference, fill = n), color = "white") +
scale_fill_gradient(low = "white", high = "blue") +
labs(x = "Predicted", y = "Actual", title = "Confusion Matrix") +
theme_minimal()
}
# Split the data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(new_york$Index_Count, p = 0.8, list = FALSE)
train_data <- new_york[trainIndex, ]
test_data <- new_york[-trainIndex, ]
# Train the model on the training set
ny_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(ny_model, newdata = test_data, type = "response")
# Convert predictions to integers (since counts cannot be fractional)
predictions <- as.integer(predictions)
# Evaluate the model's performance
cm <- confusionMatrix(predictions, test_data$Index_Count)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.7, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.9, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork$Index_Count, p = 0.8, list = FALSE)
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork$Index_Count, p = 0.8, list = FALSE)
View(newyork)
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork$yearly_crime, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
shiny::runApp()
stop
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
ggplot(data, aes(x = Predicted, y = Actual)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Predicted vs. Actual",
x = "Predicted Values",
y = "Actual Values")
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
options(scipen = 999)
set.seed(123)
train_indices <- createDataPartition(newyork_noagg$Index_Count, p = 0.8, list = FALSE)
train_data <- newyork_noagg[train_indices, ]
test_data <- newyork_noagg[-train_indices, ]
# Fit the negative binomial regression model
nb_model <- glm.nb(Index_Count ~ Unemployment + Labor + Population, data = train_data)
# Make predictions on the testing set
predictions <- predict(nb_model, newdata = test_data, type = "response")
# Evaluate model performance
performance_metrics <- postResample(predictions, test_data$Index_Count)
# Print performance metrics (you can choose different metrics)
print(performance_metrics)
# Create a visualization
png("your_plot.png", width = 800, height = 600)
plot(predictions, test_data$Index_Count, main = "Predicted vs. Actual",
xlab = "Predicted Values", ylab = "Actual Values")
abline(a = 0, b = 1, col = "red")  # Diagonal line for reference
dev.off()
runApp()
runApp()
runApp()
runApp()
setwd("X:/Coding/Rstudio/R Projects/Data 490 Model Building/Documentation")
runApp('X:/Coding/Rstudio/R Projects/Data 490 Model Building/Shiny/Final')
runApp('X:/Coding/Rstudio/R Projects/Data 490 Model Building/Shiny/Final')
getwd()
runApp('X:/Coding/Rstudio/R Projects/Data 490 Model Building/Shiny/Final')
